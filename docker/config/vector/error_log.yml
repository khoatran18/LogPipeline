sources:
  source_kafka:
    type: kafka
    bootstrap_servers: broker1:29092
    group_id: error_log
    topics:
      - error_log
    auto_offset_reset: earliest
    acknowledgements:
      enabled: true
    decoding:
      codec: bytes
    drain_timeout_ms: 2500
    fetch_wait_max_ms: 100

transforms:
  parse_json:
    type: remap
    inputs:
      - source_kafka
    drop_on_abort: true
    source: |
      .message = decode_charset!(.message, "utf-8")
      .log_type = "error_log"
      check1 = parse_regex!(.message, r'(?P<timestamp>[^\[]+)\[(?P<level>\w+)\] (?P<pid>\d+)#(?P<tid>\d+)\: \*(?P<request_id>\d+) (?P<error_message>[^,]+), client\: (?P<ip>.+)')
      check2 = parse_regex!(check1.error_message, r'(?P<action>\w+)[^\"]+\"(?P<file_path>[^\"]+)\"[^\(]+\((?P<errno>\d+).+')
      .timestamp = check1.timestamp
      .level = check1.level
      .pid = check1.pid
      .tid = check1.tid
      .request_id = check1.request_id
      .ip = check1.ip
      .error_message = check1.error_message
      .action = check2.action
      .file_path = check2.file_path
      .errno = check2.errno
      
      # "send() \"/opt/app/storage/logs/laravel.log\" aborted (32: Broken pipe)"

  split_routes:
    type: exclusive_route
    inputs:
      - parse_json
    routes:
      - name: "sample"
        condition:
          type: vrl
          source: |
            important_levels = ["crit", "error", "alert"]
            check = true
            for_each(important_levels) -> |_, level| {
              if (.level == level) {
                check = false
              }
            }
            check
      - name: "dangerous"
        condition:
          type: vrl
          source: |
            true

      - name: "dedupe"
        condition:
          type: vrl
          source: |
            true


  sample_route:
    type: sample
    inputs:
      - split_routes.sample
    ratio: 0.2
    sample_rate_key: ""

  dedupe_route:
    type: dedupe
    inputs:
      - split_routes.dedupe
    cache:
      num_events: 1000
    fields:
      match:
        - timestamp

sinks:
  console_output:
    type: console
    inputs:
      - sample_route
      - dedupe_route
      - split_routes.dangerous
    target: stdout
    encoding:
      codec: json

  kafka_output:
    type: kafka
    inputs:
      - sample_route
      - dedupe_route
      - split_routes.dangerous
    bootstrap_servers: broker1:29092
    topic: enrich_topic
    encoding:
      codec: json
    buffer:
      type: disk
      max_size: 268435490
      when_full: block

#tests:
#  - name: "Test reduce route"
#    inputs:
#      - insert_at: parse_json
#        type: log
#        log_fields:
#          message: '2025/05/31 11:00:44 [notice] 7020#3: *109 open() "/favicon.ico" failed (2: No such file or directory), client: 176.149.195.55'
#    outputs:
#      - extract_from: split_routes.sample
#        conditions:
#          - type: vrl
#            source: |
#              assert_eq!(.level, "notice", "Can be reduce")
#
#  - name: "Test dangerous route"
#    inputs:
#      - insert_at: parse_json
#        type: log
#        log_fields:
#          message: '2025/05/30 17:20:39 [crit] 2767#9: *266 flush() "/opt/app/storage/logs/laravel.log" failed (30: Read-only file system), client: 59.64.27.146'
#    outputs:
#      - extract_from: split_routes.dangerous
#        conditions:
#          - type: vrl
#            source: |
#              assert_eq!(.level, "crit", "Can be reduce")